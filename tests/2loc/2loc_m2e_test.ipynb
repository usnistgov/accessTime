{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5c1988-2f4a-4897-98e0-3e3e7596adab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "## - wrap import calls, helper functions, two location processing function, and main def into a script\n",
    "## - update naming conventions of file names AND file hirearchy\n",
    "## gsh moved output files into a new hirearchy (dummy_level), to allow the function to find the parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee8309e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, glob, json, math, os, re, shutil \n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "\n",
    "import mcvqoe\n",
    "from mcvqoe.base.terminal_user import terminal_progress_update\n",
    "from mcvqoe.timing.audio_chans import timecode_chans\n",
    "from mcvqoe.timing.timecode import time_decode\n",
    "from mcvqoe.utilities.reprocess import get_module, reprocess_file\n",
    "from mcvqoe.delay import ITS_delay_est, sliding_delay_estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38042d61-3955-4786-9d54-c39d6c04f7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper functions (need to go into 2loc processing script)\n",
    "\n",
    "#TODO test_name_parts needs updating with new conventions\n",
    "def test_name_parts(name):\n",
    "    m=re.match( r'(?P<prefix>.*capture)_'+\n",
    "                    '(?P<testtype>.+)_'+\n",
    "                    '(?P<date>\\d{2}-\\w{3}-\\d{4}_\\d{2}-\\d{2}-\\d{2})'+\n",
    "                    '(?P<ext>\\.\\w+)?$',\n",
    "                name\n",
    "              )\n",
    "    if not m:\n",
    "        raise RuntimeError(f'Unable to find test name parts from \\'{name}\\'')\n",
    "    return (m.group('prefix'),m.group('testtype'),m.group('date'))\n",
    "\n",
    "def timedelta_total_seconds(time):\n",
    "    try:\n",
    "        #try it as if it's an array\n",
    "        return [timedelta_total_seconds(t) for t in time]\n",
    "    except TypeError:\n",
    "        #not an array, must be scalar time\n",
    "        return time.days*(24*60*60) + time.seconds + time.microseconds*1e-6\n",
    "\n",
    "#function to quickly find the index of the nearest value\n",
    "#from https://stackoverflow.com/a/26026189\n",
    "def find_nearest(array,value):\n",
    "    idx = np.searchsorted(array, value, side=\"left\")\n",
    "    if idx > 0 and (idx == len(array) or math.fabs(value - array[idx-1]) < math.fabs(value - array[idx])):\n",
    "        return idx-1\n",
    "    else:\n",
    "        return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbafa0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two location processing function\n",
    "\n",
    "def twoloc_process(tx_name, extra_play=0, rx_name = None, outdir=\"\",\n",
    "                        progress_update=terminal_progress_update,\n",
    "                        align_mode='fit',\n",
    "                        **kwargs       #get kwargs to accept arbitrary arguments\n",
    "                   ):\n",
    "    '''\n",
    "    Process rx and tx files for a two location test.\n",
    "    \n",
    "    This writes a .csv file to data/csv and wave files to data/wav for a test. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tx_name : string\n",
    "        path to the transmit .csv file. If this is a relative path than\n",
    "        `[outdir]/data/csv` is searched.\n",
    "    extra_play : float, default=0\n",
    "        Extra audio to add after tx clip stopped. This mayb be used, in some\n",
    "        cases, to correct for data that was recorded with a poorly chosen\n",
    "        overplay.\n",
    "    rx_name : string, None\n",
    "        Name of the receive .wav file. If this is a relative path than\n",
    "        `[outdir]/data/csv` is searched. If this is None then `data/2loc_rx-data`\n",
    "        is searched.\n",
    "    outdir : string, default=\"\"\n",
    "        Directory that contains the `data/` folder where data will be read from\n",
    "        and written to.\n",
    "    progress_update : function, default=terminal_user\n",
    "        Function to call with updates on processing progress. \n",
    "        \n",
    "    See Also\n",
    "    --------\n",
    "        mcvqoe.mouth2ear : mouth to ear code, can produce 2 location data.\n",
    "    '''\n",
    "\n",
    "\n",
    "    #TODO: 'Validate inputs' needs updating with new conventions\n",
    "\n",
    "    #-----------------------------Validate inputs-----------------------------\n",
    "\n",
    "    #normalize path\n",
    "    tx_name = os.path.normpath(tx_name)\n",
    "\n",
    "    if os.path.isdir(tx_name):\n",
    "        #given directory, assume this is the .wav dir\n",
    "        tx_wav_path = tx_name\n",
    "        #find .csv files in the directory\n",
    "        csvs = glob.glob(os.path.join(tx_wav_path, '*.csv'))\n",
    "\n",
    "        if not csvs:\n",
    "            raise RuntimeError(f'No .csv files found in \\'{tx_wav_path}\\'')\n",
    "        elif len(csvs) > 1:\n",
    "            raise RuntimeError(f'More than one .csv file found in \\'{tx_wav_path}\\'')\n",
    "\n",
    "        tx_name = csvs[0]\n",
    "    else:\n",
    "        #get folder path from filename\n",
    "        tx_wav_path=os.path.dirname(tx_name)\n",
    "\n",
    "    #get folder name (just name, no path)\n",
    "    tx_wav_fold =  os.path.basename(tx_wav_path)\n",
    "\n",
    "    if not tx_wav_fold:\n",
    "        raise RuntimeError(f'unable to extract wav folder from \\'{tx_name}\\'')\n",
    "\n",
    "    #extract parts of tx name for validation\n",
    "    (tx_prefix,tx_tt,tx_date)=test_name_parts(tx_wav_fold)\n",
    "    #check prefix\n",
    "    if(tx_prefix != 'Tx_capture'):\n",
    "        raise ValueError(f'Unexpected filename prefix \\'{tx_prefix}\\' for tx file')\n",
    "    \n",
    "    #extra_play must be non-neg\n",
    "    if extra_play < 0:\n",
    "        raise ValueError(\"extra_play must be non negative\")\n",
    "\n",
    "    #tolerance for timecode variation\n",
    "    tc_warn_tol = 0.0001\n",
    "\n",
    "    \n",
    "    #TODO: 'Locate input data' needs updating with new conventions\n",
    "    # --------------------------[Locate input data]--------------------------\n",
    "    \n",
    "    #go two levels up from .csv file\n",
    "    tx_fold=os.path.dirname(os.path.dirname(tx_name))\n",
    "    \n",
    "    indir=os.path.abspath(os.path.join(tx_fold,'..','..'))\n",
    "    \n",
    "    #check if rx_name is a directory\n",
    "    if rx_name and os.path.isdir(rx_name):\n",
    "        #use rx_name as dir\n",
    "        rx_dir = rx_name\n",
    "        #we don't have a specific name, clear rx_name\n",
    "        rx_name = None\n",
    "    else:\n",
    "        rx_dir=os.path.join(indir,'data','2loc_rx-data')\n",
    "\n",
    "    #TODO: 'Setup Files and folders' may need to be reconfigured to have it make more sense with new conventions\n",
    "    # -----------------------[Setup Files and folders]-----------------------\n",
    "\n",
    "    # generate data dir names\n",
    "    data_dir = os.path.join(outdir, \"data\")\n",
    "    wav_data_dir = os.path.join(data_dir, \"wav\")\n",
    "    csv_data_dir = os.path.join(data_dir, \"csv\")\n",
    "\n",
    "    # create data directories\n",
    "    os.makedirs(csv_data_dir, exist_ok=True)\n",
    "    os.makedirs(wav_data_dir, exist_ok=True)\n",
    "\n",
    "    # generate base file name to use for all files\n",
    "    base_filename ='_'.join(('capture2',tx_tt,tx_date))\n",
    "\n",
    "    # generate test dir names\n",
    "    wavdir = os.path.join(wav_data_dir, base_filename)\n",
    "\n",
    "    # create test dir\n",
    "    os.makedirs(wavdir, exist_ok=True)\n",
    "\n",
    "    # generate csv name\n",
    "    csv_out_name = os.path.join(csv_data_dir, f\"{base_filename}.csv\")\n",
    "    \n",
    "    #------------------Find appropriate rx file by timecode------------------\n",
    "    #if a rx file name is not specified, find the appropriate file in rx-dat \n",
    "    #folder. if there are more than one suitable rx files based on timecode, \n",
    "    #this will find the one with the smallest delay, with delay defined as \n",
    "    #difference between the start times of the rx and tx recordings\n",
    "    \n",
    "    #if no file was specified for the rx file, search for it in rx-dat\n",
    "    if not rx_name:\n",
    "    \n",
    "        #attempt to get date from tx filename\n",
    "        print(f'The tx date is {tx_date}')\n",
    "        tx_date=datetime.strptime(tx_date, '%d-%b-%Y_%H-%M-%S')\n",
    "        \n",
    "        #rx_files is a dict with the delays as keys, and the rx path as values\n",
    "        rx_files = {}\n",
    "        progress_update('status', 0, 0, msg=f'looking for rx files in \\'{rx_dir}\\'')\n",
    "        #loop thru all rx \n",
    "        \n",
    "        for rx_file_name in glob.glob(os.path.join(rx_dir,'*.wav')):\n",
    "            progress_update('status', 0, 0, msg=f'Looking at {rx_file_name}')\n",
    "            #strip leading folders\n",
    "            rx_basename=os.path.basename(rx_file_name)\n",
    "            #split into parts\n",
    "            (rx_prefix,rx_tt,rx_date)=test_name_parts(rx_basename)\n",
    "            #validate that this is a correct rx file\n",
    "            if rx_prefix != 'Rx_capture':\n",
    "                #give error\n",
    "                progress_update('warning', 0, 0, msg=f'Rx filename \"{rx_basename}\" is not in the proper form. Can not determine Rx filename')\n",
    "                #if not a correct rx file, skip this file and go to next one\n",
    "                continue\n",
    "            rx_start_date=datetime.strptime(rx_date, '%d-%b-%Y_%H-%M-%S')\n",
    "            #add to the rx_file dict, with delays as the key, and full path as value\n",
    "            rx_files[tx_date - rx_start_date] = rx_file_name\n",
    "    \n",
    "        #create a np array of all of delays\n",
    "        delays = np.array(list(rx_files), dtype=timedelta)\n",
    "        \n",
    "        #find the smallest positive delay\n",
    "        minDelay = min(delays[delays > timedelta()])\n",
    "        \n",
    "        #find the file with the the smallest delay\n",
    "        rx_name=rx_files[minDelay]\n",
    "\n",
    "        progress_update('status', 0, 0, msg=f'Loading {rx_name}')\n",
    "\n",
    "        #read file\n",
    "        rx_fs, rx_dat = v\n",
    "    \n",
    "        #find the duration of the rx file\n",
    "        duration = timedelta(seconds=len(rx_dat)/rx_fs)\n",
    "        \n",
    "        print(duration)\n",
    "        \n",
    "        #check that tx date falls within rx file time\n",
    "        if minDelay < duration:\n",
    "            rx_name = rx_files[minDelay]\n",
    "        #otherwise there is no suitable rx file\n",
    "        else:\n",
    "            raise ValueError(\"Could not find suitable Rx file\")\n",
    "    \n",
    "    else:\n",
    "        rx_fs, rx_dat = mcvqoe.base.audio_read(rx_name)\n",
    "    \n",
    "    rx_dat=mcvqoe.base.audio_float(rx_dat)\n",
    "    \n",
    "    #--------------------Prep work for calculating delays--------------------\n",
    "\n",
    "    rx_info_name= os.path.splitext(rx_name)[0]+'.json'\n",
    "    rx_align_rec= os.path.splitext(rx_name)[0]+'_align_rec.wav' #+gsh3\n",
    "    \n",
    "    with open(rx_info_name) as info_f:\n",
    "        rx_info=json.load(info_f)\n",
    "        \n",
    "    tc_chans=timecode_chans(rx_info['channels'])\n",
    "    if not tc_chans:\n",
    "        raise ValueError(f'Timecode channel could not be found in {rx_info[\"channels\"]}')\n",
    "    \n",
    "    #use the first one\n",
    "    rx_tc_idx=tc_chans[0]\n",
    "    \n",
    "    #timecode type\n",
    "    rx_tc_type=rx_info['channels'][rx_tc_idx]\n",
    "    \n",
    "    #get channels\n",
    "    rx_extra_chans=rx_info['channels']\n",
    "    #remove timecode channel\n",
    "    del rx_extra_chans[rx_tc_idx]\n",
    "    \n",
    "    #decode the rx timecode\n",
    "    # try:\n",
    "    rx_tca = rx_dat[:,rx_tc_idx]\n",
    "    rx_time, rx_snum = time_decode(rx_tc_type,rx_tca, rx_fs)\n",
    "    \n",
    "    \n",
    "    ###### This block outputs for diagnostic purposes gsh3#######\n",
    "    def time_formatter(dt_s):\n",
    "        days = []\n",
    "        seconds = []\n",
    "        for dt in dt_s:\n",
    "            day = f\"{dt.year}_{dt.month}_{dt.day}\"  \n",
    "            days.append(day)\n",
    "            second = dt.hour*60*60 + dt.minute*60 + dt.second\n",
    "            seconds.append(second)\n",
    "        days = set(days)\n",
    "        return days, seconds\n",
    "        \n",
    "    days, seconds = time_formatter(rx_time) #\n",
    "    \n",
    "    rx_dict = {'rx_date': list(days), \n",
    "               'rx_times': seconds,  # +gsh3\n",
    "               'rx_snum': rx_snum.tolist()           # +gsh3\n",
    "              } \n",
    "    rx_time_name= os.path.splitext(rx_name)[0]+'_time.json'     \n",
    "    output_json = json.dumps(rx_dict)        # +gsh3            \n",
    "    with open(rx_time_name, 'w') as output:  # +gsh3            \n",
    "        output.write(output_json)            # +gsh3            \n",
    "   ##############################################################\n",
    "    \n",
    "    #make rx_time a numpy array\n",
    "    rx_time = np.array(rx_time)\n",
    "    \n",
    "    if align_mode == 'interpolate':\n",
    "        #we are interpolating, get reference time\n",
    "        ref_time =  rx_time[0]\n",
    "        #interpolate so we have intermediate values\n",
    "        rx_interp = np.interp(range(len(rx_dat)),rx_snum,timedelta_total_seconds(rx_time-ref_time))\n",
    "    elif align_mode == 'fit':\n",
    "        #we are fitting, get reference time\n",
    "        ref_time =  rx_time[0]\n",
    "        #fit index vs time\n",
    "        #do a linear fit of the timecode data to get time vs index\n",
    "        rx_fit = np.polyfit(timedelta_total_seconds(rx_time-ref_time), rx_snum, 1)\n",
    "        #get model\n",
    "        rx_idx_fun = np.poly1d(rx_fit)\n",
    "\n",
    "    extra_samples = extra_play * rx_fs\n",
    "\n",
    "    ### iterate through the TX CSV rows to find the timing code and align with the RX codes\n",
    "    with open(tx_name,'rt') as tx_csv_f, open(csv_out_name,'wt',newline='') as out_csv_f:\n",
    "        \n",
    "        #create dict reader\n",
    "        reader=csv.DictReader(tx_csv_f)\n",
    "        \n",
    "        #create dict writer, same fields as input\n",
    "        writer=csv.DictWriter(out_csv_f,reader.fieldnames)\n",
    "        \n",
    "        #write output header\n",
    "        writer.writeheader()\n",
    "        \n",
    "        #get data from file\n",
    "        #NOTE : this may not work well for large files! but should, typically, be fine\n",
    "        rows = tuple(reader)\n",
    "        \n",
    "        #get total trials for progress\n",
    "        total_trials = len(rows)\n",
    "    \n",
    "        #loop through all tx recordings\n",
    "        for trial,row in enumerate(rows):\n",
    "            \n",
    "            progress_update('proc', total_trials, trial)\n",
    "            \n",
    "            tx_rec_name = f'Rx{trial+1}_{row[\"Filename\"]}.wav'\n",
    "            full_tx_rec_name = os.path.join(tx_wav_path, tx_rec_name)\n",
    "\n",
    "            #check if file exists\n",
    "            # if not os.path.exists(clip_path): gsh3\n",
    "            if not os.path.exists(full_tx_rec_name): #+gsh3\n",
    "                #update progress\n",
    "                progress_update('status', total_trials, trial,\n",
    "                msg = f\"{full_tx_rec_name} not found\")\n",
    "                #unzip audio if it exists\n",
    "                # mcvqoe.base.Measure.unzip_audio(audio_path) #-gsh3\n",
    "\n",
    "            tx_rec_fs, tx_rec_dat = mcvqoe.base.audio_read(full_tx_rec_name)\n",
    "\n",
    "            #check that audio sampling rate is the same  +gsh3\n",
    "            if rx_fs != tx_rec_fs:\n",
    "                 raise ValueError(f'RX and TX sampling not the same for {tx_wav_path}')\n",
    "\n",
    "            #make floating point for processing purposes\n",
    "            tx_rec_dat=mcvqoe.base.audio_float(tx_rec_dat)\n",
    "            \n",
    "            tx_rec_chans=mcvqoe.base.parse_audio_channels(row['channels'])\n",
    "            \n",
    "            if(len(tx_rec_chans)==1):\n",
    "                #only one channel, make sure that it's a timecode\n",
    "                if('timecode' not in tx_rec_chans[0]):\n",
    "                    raise ValueError(f'Expected timecode channel but got {row[\"channels\"][0]}')\n",
    "                \n",
    "                #make sure that timecode types match\n",
    "                if rx_tc_type != tx_rec_chans[0]:\n",
    "                    raise ValueError(f'Tx timecode type is {tx_rec_chans[0]} but Rx timecode type is {rx_tc_type}')\n",
    "                \n",
    "                #one channel, only timecode\n",
    "                tx_rec_tca=tx_rec_dat\n",
    "                \n",
    "                tx_extra_audio = None\n",
    "                tx_extra_chans = None\n",
    "            else:                \n",
    "                #grab the same type of timecode we used for Rx\n",
    "                tx_time_idx = tx_rec_chans.index(rx_tc_type)\n",
    "\n",
    "                tx_rec_tca = tx_rec_dat[:,tx_time_idx]\n",
    "\n",
    "                #extra channels\n",
    "                tx_extra_audio = np.delete(tx_rec_dat,tx_time_idx,1)\n",
    "\n",
    "                #copy to new array without timecode channel\n",
    "                tx_extra_chans = list(tx_rec_chans)\n",
    "                del tx_extra_chans[tx_time_idx]\n",
    "                \n",
    "            \n",
    "            #decode timecode\n",
    "            tx_time, tx_snum = time_decode(rx_tc_type, tx_rec_tca, tx_rec_fs)\n",
    "\n",
    "\n",
    "            ##### diagnostic block from gsh3 ######################################\n",
    "            \n",
    "            # #tx_json_wriiter ### from gsh3\n",
    "            # days, seconds = time_formatter(tx_time)\n",
    "    \n",
    "            # tx_dict = {'tx_date': list(days), \n",
    "            #            'tx_times': seconds,  # +gsh3\n",
    "            #            'tx_snum': tx_snum.tolist()           # +gsh3\n",
    "            #           }\n",
    "            \n",
    "            # output_json = json.dumps(tx_dict)        # +gsh3\n",
    "            # with open(f\"{row['Filename']}_{row['Timestamp']}.json\", 'w') as output:\n",
    "            #     output.write(output_json)            # +gsh3\n",
    "            #########################################################################\n",
    "            \n",
    "            \n",
    "            if align_mode == 'fixed':\n",
    "                #array for matching sample numbers\n",
    "                tx_match_samples = []\n",
    "                rx_match_samples = []\n",
    "\n",
    "\n",
    "                for time,snum in zip(tx_time,tx_snum):\n",
    "                    \n",
    "                    #calculate difference from rx timecode\n",
    "                    time_diff = abs(rx_time - time)\n",
    "                    \n",
    "                    #find minimum difference\n",
    "                    min_v = np.amin(time_diff)\n",
    "\n",
    "                    #check that difference is small\n",
    "                    if min_v < timedelta(seconds=0.5):\n",
    "\n",
    "                        #get matching index\n",
    "                        idx=np.argmin(time_diff)\n",
    "\n",
    "                        #append sample number\n",
    "                        tx_match_samples.append(snum)\n",
    "                        rx_match_samples.append(rx_snum[idx])\n",
    "\n",
    "                #get matching frame start indicies\n",
    "                mfr=np.column_stack((tx_match_samples, rx_match_samples))\n",
    "\n",
    "                #get difference between matching timecodes\n",
    "                mfd=np.diff(mfr, axis=0)\n",
    "\n",
    "\n",
    "                #get ratio of samples between matches\n",
    "                mfdr = mfd[:,0] / mfd[:,1]\n",
    "\n",
    "            \n",
    "                if not np.all(np.logical_and(mfdr < (1+tc_warn_tol), mfdr>(1-tc_warn_tol))):\n",
    "                    progress_update('warning', total_trials, trial, f'Timecodes out of tolerence for trial {trial+1}. {mfdr}')\n",
    "\n",
    "                #calculate first rx sample to use\n",
    "                first=mfr[0,1]-mfr[0,0]\n",
    "\n",
    "                #calculate last rx sample to use\n",
    "                last=mfr[-1,1]+len(tx_rec_tca)-mfr[-1,0]+extra_samples - 1\n",
    "            elif align_mode == 'interpolate' or align_mode =='fit':\n",
    "                tx_tnum =timedelta_total_seconds(tx_time - ref_time)\n",
    "\n",
    "                #do a linear fit of the timecode data to get index vs time\n",
    "                fit = np.polyfit(tx_snum, tx_tnum, 1)\n",
    "                #get model\n",
    "                tc_fun = np.poly1d(fit)\n",
    "\n",
    "                #get time of start and end of tx clip\n",
    "                tx_start_time = tc_fun(0)\n",
    "                tx_end_time = tc_fun(len(tx_rec_tca) + extra_samples - 1)\n",
    "\n",
    "                if align_mode == 'interpolate':\n",
    "                    #get indices in the Rx array\n",
    "                    first = find_nearest(rx_interp, tx_start_time)\n",
    "                    last  = find_nearest(rx_interp, tx_end_time)\n",
    "                elif align_mode == 'fit':\n",
    "                    first = math.floor(rx_idx_fun(tx_start_time))\n",
    "                    last  = math.ceil(rx_idx_fun(tx_end_time))\n",
    "\n",
    "            else:\n",
    "                raise ValueError(f'Invalid value, \\'{align_mode}\\' for align_mode')\n",
    "            #get rx recording data from big array\n",
    "            rx_rec=rx_dat[first:last+1,:]\n",
    "            #remove timecode\n",
    "            rx_rec = np.delete(rx_rec,rx_tc_idx,1)\n",
    "            #diagnostic output gsh3\n",
    "            mcvqoe.base.audio_write(rx_align_rec, 48000, rx_rec)\n",
    "            \n",
    "            \n",
    "            if tx_extra_chans:\n",
    "                #add tx extra chans to rx extra chans\n",
    "                out_chans=tuple(rx_extra_chans+tx_extra_chans)\n",
    "\n",
    "                #get the length of the longest array\n",
    "                new_len = np.max((rx_rec.shape[0],tx_extra_audio.shape[0]))\n",
    "\n",
    "                #resize recording\n",
    "                rec_shape = list(rx_rec.shape)\n",
    "                rec_shape[0] = new_len\n",
    "                rx_rec.resize( tuple(rec_shape))\n",
    "\n",
    "                #resize tx extra\n",
    "                tx_shape = list(tx_extra_audio.shape)\n",
    "                tx_shape[0] = new_len\n",
    "                tx_extra_audio.resize( tuple(tx_shape))\n",
    "\n",
    "                #both arrays should now be the same length (in time)\n",
    "                out_audio=np.column_stack((rx_rec,tx_extra_audio))\n",
    "            else:\n",
    "                #no extra chans, all out chans from rx\n",
    "                out_chans=rx_extra_chans\n",
    "                out_audio=rx_rec\n",
    "            \n",
    "            #overwrite new channels to csv\n",
    "            row['channels']=mcvqoe.base.audio_channels_to_string(out_chans)\n",
    "            \n",
    "            ## find the phrase file if only the timing is present\n",
    "            if tx_extra_audio is None:\n",
    "                full_tx_phrase_name = os.path.join(tx_wav_path, 'Tx_' + row['Filename'] + '.wav')\n",
    "                if not os.path.exists(full_tx_phrase_name):\n",
    "                    raise ValueError(f'cannot find {full_tx_phrase_name}')\n",
    "                \n",
    "                tx_phrase_fs, tx_phrase_dat = mcvqoe.base.audio_read(full_tx_phrase_name)\n",
    "                if tx_phrase_fs != rx_fs:\n",
    "                    raise ValueError(f'RX and TX sampling not the same for {full_tx_phrase_name}')\n",
    "                tx_extra_chans = mcvqoe.base.audio_float(tx_phrase_dat)\n",
    "            \n",
    "            rx_phrase = np.concatenate(rx_rec)\n",
    "       \n",
    "            ###### this block from gsh3 ########\n",
    "            \n",
    "            #run delay with final position, and the number of samples at which audio aligns\n",
    "            (pos, delay_points) = ITS_delay_est(tx_extra_chans, \n",
    "                                                rx_phrase, \n",
    "                                                'f', \n",
    "                                                fs=rx_fs, \n",
    "                                                dlyBounds=[np.NINF, np.inf], \n",
    "                                                min_corr=0)\n",
    "\n",
    "            delay_time = delay_points/tx_phrase_fs \n",
    "            row['m2e_latency'] = delay_time \n",
    "            ###################################\n",
    "\n",
    "            \n",
    "            # Create audiofile name/path for recording\n",
    "            audioname = f'Rx{trial+1}_{row[\"Filename\"]}.wav'\n",
    "            audioname = os.path.join(wavdir, audioname)\n",
    "\n",
    "            \n",
    "            #save out Rx recording as given data type\n",
    "            mcvqoe.base.audio_write(audioname,rx_fs,out_audio)\n",
    "                \n",
    "            #write row to new .csv\n",
    "            writer.writerow(row)\n",
    "        \n",
    "        #copy Tx files into destination folder\n",
    "        for name in glob.glob(os.path.join(tx_wav_path,'Tx_*')):\n",
    "            #get clip name from path\n",
    "            clip_name=os.path.basename(name)\n",
    "            #construct destination name\n",
    "            destname=os.path.join(wavdir,clip_name)\n",
    "            #copy file\n",
    "            shutil.copyfile(name,destname)\n",
    "\n",
    "    #return output filename\n",
    "    return csv_out_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "732dabae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test data\n",
      "Processing trial 0 of 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'data/csv/capture2_2loc_26-Sep-2023_12-44-16.csv'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calls the 2 loc processing function, should NOT go in wraped script\n",
    "twoloc_process(\n",
    "               tx_name = 'dummy_level_1/dummy_level_2/Tx_capture_2loc_26-Sep-2023_12-44-16',\n",
    "               rx_name = 'data/2loc_rx-data/Rx_capture_2loc_26-Sep-2023_12-44-18.wav',\n",
    "               align_mode ='fit') # only 'fit' and 'fixed' are working correctly \n",
    "\n",
    "## this function will produce a set of JSONs (e.g., 'F1_harvard_phrases_26-Sep-2023 12/44/29.json') to be analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecdd536e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: xpython [-h] [--extra-play EXTRA_PLAY] [--rx-name RX_NAME] [--outdir OUTDIR] [-m M] tx_name\n",
      "xpython: error: unrecognized arguments: -f\n",
      "/Users/gsh3/miniconda3/envs/jupyterlab-debugger/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3556: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    },
    {
     "ename": "<class 'SystemExit'>",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "## defining main (from original script)\n",
    "\n",
    "def main():\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument(\"tx_name\",\n",
    "                        type=str,\n",
    "                        help='Name of the Tx .csv file to process/'\n",
    "                        )\n",
    "    parser.add_argument(\"--extra-play\",\n",
    "                        type=int,\n",
    "                        default=0,\n",
    "                        help='Duration of extra audio to add after tx clip '+\n",
    "                        'stopped. This mayb be used, in some cases, to correct '+\n",
    "                        'for data that was recorded with a poorly chosen overplay.'\n",
    "                        )\n",
    "    parser.add_argument(\"--rx-name\",\n",
    "                        type=str,\n",
    "                        default=None,\n",
    "                        help='Filename of the rx file to use. If a directory '+\n",
    "                        'is given, it will be searched for files'\n",
    "                        )\n",
    "    parser.add_argument(\"--outdir\",\n",
    "                        type=str,\n",
    "                        default=\"\",\n",
    "                        help='Root of directory structure where data will be stored'\n",
    "                        )\n",
    "    parser.add_argument('-m', '--measurement',\n",
    "                        type=str,\n",
    "                        default=None,\n",
    "                        metavar='M',\n",
    "                        help='measurement to use to do reprocessing'\n",
    "                        )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    #try to load measurement class\n",
    "    try:\n",
    "        measurement_class = get_module(module_name=args.measurement, datafile=args.tx_name)\n",
    "    except (RuntimeError,KeyError) as e:\n",
    "        terminal_progress_update('warning', 0, 0, msg=f'Unable to determine measurement. Output file will not be processed')\n",
    "        #set measurement class for later\n",
    "        measurement_class = None\n",
    "\n",
    "    out_name = twoloc_process(**vars(args))\n",
    "\n",
    "    if measurement_class:\n",
    "        #create test obj to reprocess with\n",
    "        test_obj=measurement_class()\n",
    "\n",
    "        reprocess_file(test_obj, out_name, out_name)\n",
    "\n",
    "        print(f'Reprocessing complete for \\'{out_name}\\'')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a459cd7-00a0-4acd-939c-1fa70f69b317",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
